\chapter{Testes}
Três baterias de testes foram conduzidas ao longo da produção deste trabalho de graduação a fim de ver na prática o
impacto dos algoritmos de aprendizado de máquina quando aplicados em bases de dados com informações de rede.
Em um dos testes, a base utilizada foi a supracitada KDD Cup 99. Para os outros, utilizou-se uma série de dados
 gerados pelo mestrando da PUC-PR Eduardo, orientado pelo Pr. Dr. Altair. Em ambos os casos, os algoritmos foram
 executados através do Weka.

\section{Weka}
O \textit{Waikato Environment for Knowledge Analysis} (Weka) é uma suíte de aplicações para aprendizagemd e máquina e
mineiração de dados. O software foi desenvolvido em Java na \textit{University of Waikato} e lincenciado sob a
\textit{GNU General Public License}. Os destaques dessa ferramenta incluem a vasta quantidade de algoritmos
implementados, pré-processamento de dados, seleção de atributos e visualização de dados. O Weka funciona como uma
interface, permitindo que novos algoritmos em Java sejam produzidos e facilmente executados de forma gráfica e com
resultados interativos \cite{bouckaert10}.

\section{Avaliação de Performance}
Gráficos ROC (\textit{Receiver Operating Characterístics}) são comumente usados como um método  para visualizar
a performance de classificadores e analisar as taxas de acertos e alarmes falsos \cite{fawcett04}. A Um gráfico ROC
baseia-se em apenas duas classes: positivo ou negativo. Em termos de detecção de intrusão, uma conexão pode ser
considerada inofensiva (positivo) ou prejudicial (negativa). Para avaliar a precisão de um classificador,
duas outras categorias podem ser usadas: verdadeiro ou falso. Quando cruzadas, obtém-se quatro possíveis resultados,
como mostra a tabela \ref{table:tfpn}.

\begin{table}[h]
    \begin{tabular}{l|l|l|}
        \cline{2-3}
                                                               & \cellcolor[HTML]{EFEFEF}Verdadeiro (T)                                                           & \cellcolor[HTML]{EFEFEF}Falso (F)                                                     \\ \hline
        \multicolumn{1}{|l|}{\cellcolor[HTML]{EFEFEF}Positivo} & \begin{tabular}[c]{@{}l@{}}TP -- Conexão inofensiva é \\ classificada corretamente\end{tabular}  & \begin{tabular}[c]{@{}l@{}}FP -- Conexão anômala é \\ considerada normal\end{tabular} \\ \hline
        \multicolumn{1}{|l|}{\cellcolor[HTML]{EFEFEF}Negativo} & \begin{tabular}[c]{@{}l@{}}TN -- Conexão prejudicial é \\ classificada corretamente\end{tabular} & \begin{tabular}[c]{@{}l@{}}FN -- Conexão normal é \\ considerada anômala\end{tabular} \\ \hline
    \end{tabular}
    \caption{Categorias para análise de corretude}
    \label{table:tfpn}
\end{table}

Quando se sabe a verdadeira natureza dos casos de teste, é possível determinar a precisão, a taxa de Verdadeiro Positivo
 ($TP_{rate}$) e taca de Falso Positivo ($FP_{rate}$). É possível inferir que uma das maiores preocupações ao se construir
 um A-NIDS é a minimização a taxa de Falso Positivo. Teoricamente se 100\% das conexões forem consideradas anômalas
 e bloqueadas, teremos $FP_{rate}$ igual a 0. Por um lado, o sistema estaria bloqueando conexões inofensivas, por outro,
 estaria com certeza evitando conexões ameaçadores. O cálculo das taxas se dá da seguinte maneira.

 $$ Precisão = \frac{TP + TN}{P + N} $$
 $$ TP_{rate} = \frac{TP}{P} $$
 $$ FP_{rate} = \frac{FP}{N} $$

Essas taxas estão contidas no espaço entre $0$ e $1$, inclusivo, e são utilizadas para plotar o ROC. A $TP_{rate}$ é
usado no eixo $y$ e a $FP_{rate}$, no eixo $x$. Portanto, o gráfico ROC elicita a relação entre Verdadeiro Positivo e
Falso Positivo.
\par A \ref{fig:roc} mostra uma curva ROC simples com 5 classificadores fictícios: A, B, C, D e E. Cada classificador
retorna um único ponto no espaço ROC. Se o ponto estiver localizado na coordenada (0,0), como o classificador A na
\ref{fig:roc}, significa que nenhum caso foi considerado inofensivo. Classificadores que se encontram próximos ao eixo
$y$ podem ser considerados "conservadores", uma vez que necessitam de forte evidência para categorizar uma ocorrência
como positiva. Em contrapartida, o ponto B, posicionado em (1,1), representa sistemas que não acusaria nenhuma
conexão como anômala. Classificadores mais À direita do gráfico podem ser considerados "liberais" pois presumem como
positivo mais facilmente.
\par Um classificador perfeito resultaria no ponto (0,1), onde C se encontra. Isso significaria possuir $FP_{rate}$ de
0\% e $TP_{rate}$ de 100\%, ou seja, todas as conexões intrusivas serem detectadas e nenhuma conexão normal ser
bloqueada pelo sistema. Assim sendo, quanto maior o $TP_{rate}$ e menor o $FP_{rate}$, mais preciso é o algoritmo.
 Se um classificador está localizado abaixo da linha diagonal ($y = x$), isto significa que sua performance é pior do
 que a escolha aleatória de classes. O triângulo inferior direito é geralmente encontrado vazio pois em casos de
 classificação binária com alta taxa de erro, é possível simplesmente inverter os resultados. Portanto, E (0.8,0.2)
 seria tão preciso quanto D(0.2,0.8)


\section{Impacto de modelos representativos}
O primeiro teste realizado levou em consideração apenas o SVM padrão fornecido pelo libSVM para o Weka. A finalidade
era verificar o impacto da representabilidade da base de treino \cite{yaman11}, analisando a performance do algoritmo
quando treinado com bases de diferentes tamanhos. Para esse estudo, o KDD Cup 99 foi divido em 5 particionamentos,
cada um com tamanhos distintos de bases de treino e de testes, usando a opção de \textit{cross-validation} do Weka.
O comando executado incluiu um pré-processamento de heurística de encolhimento, peso $1$, \emph{seed} de $3$, erro de
$0.001$ e função núcleo \textit{Radial Basis}.

\begin{table}[h]
    \begin{tabular}{l|l|l|l|l|}
        \cline{2-5}
                                                        & \multicolumn{1}{c|}{\cellcolor[HTML]{EFEFEF}Tamanho Treino} & \multicolumn{1}{c|}{\cellcolor[HTML]{EFEFEF}Tamanho Teste} & \multicolumn{1}{c|}{\cellcolor[HTML]{EFEFEF}Tempo} & \multicolumn{1}{c|}{\cellcolor[HTML]{EFEFEF}Precisão} \\ \hline
        \multicolumn{1}{|l|}{\cellcolor[HTML]{EFEFEF}1} & 10\%                                                        & 90\%                                                       & 16h13m                                             & 92.22\%                                               \\ \hline
        \multicolumn{1}{|l|}{\cellcolor[HTML]{EFEFEF}2} & 20\%                                                        & 80\%                                                       & 24h02m                                             & 94.54\%                                               \\ \hline
        \multicolumn{1}{|l|}{\cellcolor[HTML]{EFEFEF}3} & 30\%                                                        & 70\%                                                       & 27h32m                                             & 95.65\%                                               \\ \hline
        \multicolumn{1}{|l|}{\cellcolor[HTML]{EFEFEF}4} & 40\%                                                        & 60\%                                                       & 32h11m                                             & 98.62\%                                               \\ \hline
        \multicolumn{1}{|l|}{\cellcolor[HTML]{EFEFEF}5} & 50\%                                                        & 50\%                                                       & 38h45m                                             & 99.64\%                                               \\ \hline
    \end{tabular}
    \caption{Comparação entre particionamentos de tamanhos diferentes}
    \label{table:partic}
\end{table}

\par A \ref{table:partic} mostra os as proporções de base de testes e treino em cada particionamento e seus respectivos
resultados. É possível notar uma clara correlação entre o tamanho da base de treino e a porcentagem de acertos. O
melhor resultado foi de $99.64$\% quando metade da base foi usada para gerar o modelo. Entretanto, em uma situação real
não dados disponíveis o suficiente para se representar metade das transmissões que ocorrem diariamente.


\section{Impacto da imprevisibilidade}
Uma abordagem recente direcionou os estudos desse trabalho para a análise da real capacidade de algoritmos de
aprendizado de máquinas em se adaptar a novas realidades e  detectar ameaças totalmente desconhecidas \cite{sommer10}.

\section{Impacto da seleção de atributos}
