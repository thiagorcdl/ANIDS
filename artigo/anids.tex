\chapter{Sistemas baseadoes em Anomalia}
\label{ch:anids}
 A técnica de detecção de anomalia analisa o atual comportamento da rede para checar se corresponde ou não a um
 comportamento normal. O maior benefício desse método é a habilidade de identificar novos ataques com sucesso.
 A desvantagem é a alta taxa de Falso Positivo. Ao invés de requerer um novo modelo a ser adaptado, sistemas baseados
 em anomalia necessitam de dados de tráfego de rede livres de ataques. \textit{Data mining} também tem sido
 utilizado em sistemas baseados em anomalia, junto a outros métodos estatísticos e de \textit{machine learning}
 (aprendizado de máquina).
 \par As diferentes técnicas podem ser agrupadas em três categorias, de acordo com o processamento envolvido:
 estatístico, knowledge-based (baseado em conhecimento) ou algoritmos de aprendizado de máquina.

\section{Técnicas Estatísticas}
Um modelo de probabilidade de um determinado comportamento é criado a partir da atividade capturada do tráfego de rede,
 tal como taxa de tráfego, número de pacotes e quantidade de endereços de IP distintos.
 \par Ele não requer conhecimento prévio pois está capacitado a aprender o comportamento normal a partir de observações
 sem ataques. Outro benefício das técnicas estatísticas é a possibilidade de identificar, com precisão, atividades
 maliciosas que ocorrem ao longo de períodos de tempo mais extensos. Por outro lado, nem todos os possíveis
 comportamentos conseguem ser modelados e o equilíbrio entre taxas de Falso Positivo e Falso Negativo dependem
 fortemente na configuração correta dos parâmetros.

 \section{Técnicas Baseadas em Conhecimento}
 Também chamados de \emph{expert systems}, sistemas baseados em conhecimento são implementados criando-se um conjunto de
 regras de classificação para categorizar os dados. O modelo é geralmente criado por um humano experiente no campo
 da aplicação. Esse tipo de sistema não aponta novas atividades inofensivas como sendo maliciosas, garantindo, assim,
 um número reduzido de Falso Positivo. Por essa razão, o conjunto de regras precisa ser específico o suficiente e,
 apesar de ser possível atingir um certo nível de automação usando uma máquina de estados finitos, requer
 grande conhecimento sobre o comportamento da rede e tempo significativo para ser desenvolvido.

 \section{Técnicas de Machine Learning}
 Métodos de aprendizado de máquina exigem um conjunto de dados categorizados para treinar o modelo do comportamento
 esperado. A característica principal dessa técnica é a habilidade de adaptar suas regras de classificação à medida que
 novos dados são recebidos. Isso garante pouca necessidade por intervenção humana, uma vez funcionando. O lado ruim
 do aprendizado de máquina é o alto custo computacional. Os algoritmos mais populares usados em A-NIDS são:
\emph{Support Vector Machines}; Árvores de Decisão; Redes Neurais; Rede Bayesiana; e \emph{Clustering}.

    \subsection{Support Vector Machine}
    SVM (\emph{Support Vector Machine}) trabalha mapeando a base de treino em um espaço vetorial de maior dimensionalidade para aumentar a discriminabilidade.
    Ele se baseia em minimizar o risco estrutural, ou seja, evitar que o modelo gerado fique muito específico para a base de treino \cite{lin12}.
    O SVM utiliza a base de treino para gerar um hiperplano que serve como uma fronteira para separar todas as instâncias em dois grupos; um para cada classe
    Os dados de teste são mapeados por uma \textit{função núcleo}, a qual é geralmente escolhida entre \textit{linear},
    \textit{polinomial}, \textit{sigmoide} ou \textit{radial basis}. A última é preferida no uso em SVM por usa capacidade de lidar com dados de alta dimensionalidade \cite{lin12}.

    \subsection{Árvore de Decisão}
    DT (\emph{Decision Tree}) é um método de classificação baseado em um algoritmo guloso, utilizando uma estratégia de divisão e conquista \cite{lin12}. Ele
    cria uma árvore de decisão contando com um nó raiz, que é usado para selecionar o atributo com a informação de maior valor;
    nós internos, que correspondem às características; arestas, que são os possíveis valores de cada característica; e
    folhas, que contêm a classe a ser atribuída ao caso de teste \cite{benferhat05}.

    \subsection{Redes Neurais}
    Redes neurais possuem grande adaptabilidade e são formadas por uma cadeira de perceptrons, também conhecido como MLP
    (Multilayer Perceptron). O algoritmo supervisionado passa duas vezes pela rede. Na ida, é aplicado um padrão de
    atividade nos perceptrons de entrada, que repassam para as camadas seguintes utilizando pesos pré-definidos. Na volta,
     o erro calculado é propagado para trás, fazendo com que os pesos dos perceptrons sejam ajustados.
     Uma técnica é inicializar os pesos com valores aleatórios entre $-0.5$ e $0.5$ para se evitar taxas de aprendizado
     pequenas (que disperdiçam recursos) e taxas muit altas (que demoram para treinar) \cite{barapatre08}.

    \subsection{Rede Bayesiana}
        Cria uma rede de relações de probabilidade entre características.

    \subsection{Clustering}
        Algoritmo não-supervisionado que agrupa dados com base em suas similaridades.

\section{Combinação de Classificadores}
Como cada método possui seus pontos fortes e pontos fracos, uma ideia bastante estudada no meio acadêmico é a
 combinação de classificadores. Tais combinações podem se dar de diversas maneiras, como por exemplo: Classificadores
 Híbridos, Composição de Classificadores \footnote{Tradução livre do termo em inglês Ensemble Classifiers.} e
 Classificadores em Cascata.

 \subsection{Classificadores Híbridos}
    Um classificador híbrido consiste de dois componentes. O primeiro pré-processa o dado de entrada e envia ao segundo
    classificador, que chega ao resultado final. O primeiro componente de classificadores híbridos pode ser usado tanto
    como uma técnica de clustering para achar as classes que o segundo componente utilizará para categorizar os dados;
    quanto como um otimizador de desempenho para o segundo modelo, o que corresponderia ao método \textit{integrado}
    \cite{aydin09}.


 \subsection{Classificadores em Cascata}
    Pode ser considerado uma extensão dos classificadores híbridos, podendo consistir de inúmeros classificadores, onde
    o n-ésimo classificador utiliza como entrada os dados rejeitados pelo classificador anterior, ou seja, que não
    atingiram um grau de certeza satisfatório. Alguns estudos sugerem otimização de \emph{thresholds} para aumentar precisão
    \cite{oliveira05}.

 \subsection{Composição de Classificadores}
    Uma composição de classificadores pode ser obtida usando-se técnicas fracas de aprendizado
    (geralmente mais rápidas). Cada classificador é treinado usando um subconjunto distinto dos dados.
    A base de testes é, então, processada por todos eles e, finalmente, categorizados pela maioria.


\chapter{Sistemas A-NIDS funcionais}
    O estudo feito em \cite{teodoro09} apresenta sistemas A-NIDS divididos em duas categorias: comerciais e de pesquisa.
    Sistemas comerciais geralmente trabalham com um núcleo baseado em assinatura, enquanto sistemas de pesquisa
    desenvolvem protótipos e buscam metodologias inovadoras.

 \section{Arquitetura}
    Enquanto alguns detalhes de implementação podem variar, o padrão da esquematização básica de um A-NIDS
    é como apresentado em \cite{catania12}:
    \begin{itemize}
        \item Aquisição de dados de tráfego -- coleta informação sobre os quadros da rede para processamento futuro.
        \item Gerador de características do tráfego -- extrai características do tráfego capturado. Tais características
         podem ser classificadas como "baixo nível" (obtidas diretamente do dado bruto), "alto nível" (deduzidas de um
         processamento subsequente), "pacote" (coletadas de cabeçalhos de pacotes), "fluxo" (contendo informação das
         conexões) e "payload" (obtidos da carga do pacote).
        \item Detector de incidente -- identifica atividades intrusivas. Pode ou não conter um segundo núcleo baseado
        em assinatura.
        \item Gerador de modelo de tráfego -- contém informação base usada para guiar o detector de incidente.
        \item Gerenciamento de resposta -- inicia manobras para superar uma intrusão em potencial. É inicializado pelo
        detector de incidente.
    \end{itemize}

 \section{Comercialmente}
 Um dos primeiros projetos de detecção de anomalia a ser amplamente conhecido foi o SPADE, um plugin para o Snort que
 analisava transferência de pacotes procurando comportamentos fora do comum. Alternativamente, Stealthwatch utilizava
 detecção de anomalia baseada em fluxo.
 \par Sistemas recentes usam uma arquitetura distribuída utilizando sensores e um
 console central para gerenciar o processo de detecção. Esse é o caso do DeepSight, que usa um método estatístico.
 A maioria dos sistemas comerciais utilizam um módulo de detecção baseado em assinatura aliado com um núcleo baseado em
 anomalia. Todos esses sistemas se enquadram na categoria de classificadores híbridos.